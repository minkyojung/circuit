# ğŸ¤ ìŒì„± ê¸°ëŠ¥ êµ¬í˜„ ê°€ì´ë“œ (Week 1 Day 1-2 ì™„ë£Œ)

## âœ… ì™„ë£Œëœ ì‘ì—…

### 1. íƒ€ì… ì •ì˜
- **circuit/src/types/voice.ts**
  - VoiceCommandParseResult
  - AgentTask
  - VoiceInputState
  - VoiceFeedbackState
  - MultiAgentState
  - VoiceSettings

### 2. React Context
- **circuit/src/contexts/VoiceContext.tsx**
  - VoiceProvider
  - useVoice hook
  - ë…¹ìŒ ìƒíƒœ ê´€ë¦¬
  - ìŒì„± í”¼ë“œë°± í ì‹œìŠ¤í…œ
  - ë©€í‹° ì—ì´ì „íŠ¸ ìƒíƒœ ê´€ë¦¬

### 3. UI ì»´í¬ë„ŒíŠ¸
- **circuit/src/components/voice/VoiceButton.tsx**
  - ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ ë²„íŠ¼
  - ë…¹ìŒ ì‹œê°„ í‘œì‹œ
  - ì·¨ì†Œ ë²„íŠ¼

- **circuit/src/components/voice/TranscriptionDisplay.tsx**
  - ì „ì‚¬ ê²°ê³¼ í‘œì‹œ
  - ì‹ ë¢°ë„ í‘œì‹œ

### 4. Electron ë°±ì—”ë“œ
- **circuit/electron/voice/whisper.js**
  - Whisper API í†µí•©
  - transcribeAudio() í•¨ìˆ˜

- **circuit/electron/voice/audioCapture.js**
  - ë…¹ìŒ ìƒíƒœ ê´€ë¦¬
  - íŒŒì¼ ì €ì¥ ì²˜ë¦¬

- **circuit/electron/voice/ipcHandlers.js**
  - voice:start-recording
  - voice:stop-recording
  - voice:cancel-recording
  - voice:synthesize (stub)
  - voice:play-audio (stub)
  - multi-agent:execute (stub)

---

## ğŸ”§ í†µí•© ë°©ë²•

### Step 1: main.cjsì— Voice í•¸ë“¤ëŸ¬ ë“±ë¡

**circuit/electron/main.cjs** íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€:

```javascript
// íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
const { registerVoiceHandlers } = require('./voice/ipcHandlers')

// app.whenReady() ë¸”ë¡ ë‚´ì— ì¶”ê°€ (ê¸°ì¡´ IPC í•¸ë“¤ëŸ¬ ë“±ë¡ í›„)
app.whenReady().then(async () => {
  // ... ê¸°ì¡´ ì½”ë“œ ...

  // Voice IPC í•¸ë“¤ëŸ¬ ë“±ë¡
  registerVoiceHandlers()

  // ... ê¸°ì¡´ ì½”ë“œ ...
})
```

### Step 2: App.tsxì— VoiceProvider ì¶”ê°€

**circuit/src/App.tsx** íŒŒì¼ ìˆ˜ì •:

```typescript
import { VoiceProvider } from '@/contexts/VoiceContext'

// ... ê¸°ì¡´ ì½”ë“œ ...

function App() {
  return (
    <SettingsProvider>
      <VoiceProvider>  {/* ì¶”ê°€ */}
        <Router>
          {/* ... ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ ... */}
        </Router>
      </VoiceProvider>  {/* ì¶”ê°€ */}
    </SettingsProvider>
  )
}
```

### Step 3: ChatInputì— VoiceButton ì¶”ê°€

**circuit/src/components/workspace/ChatInput.tsx** íŒŒì¼ ìˆ˜ì •:

```typescript
import { VoiceButton } from '@/components/voice/VoiceButton'
import { TranscriptionDisplay } from '@/components/voice/TranscriptionDisplay'
import { useVoice } from '@/contexts/VoiceContext'

// ... ì»´í¬ë„ŒíŠ¸ ë‚´ë¶€ ...

const { inputState } = useVoice()

// Control barì— VoiceButton ì¶”ê°€ (íŒŒì¼ ì²¨ë¶€ ë²„íŠ¼ ì˜†)
<div className="flex items-center gap-2">
  <FileInput ... />
  <VoiceButton size="sm" />  {/* ì¶”ê°€ */}
  <Button>Send</Button>
</div>

// ì „ì‚¬ ê²°ê³¼ í‘œì‹œ (input ìœ„)
{inputState.finalTranscription && (
  <TranscriptionDisplay className="mb-2" />
)}
```

ì „ì‚¬ëœ í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì…ë ¥ì°½ì— ë„£ìœ¼ë ¤ë©´:

```typescript
const { inputState } = useVoice()

useEffect(() => {
  if (inputState.finalTranscription) {
    // ì „ì‚¬ ê²°ê³¼ë¥¼ inputì— ìë™ ì…ë ¥
    setValue(inputState.finalTranscription)
  }
}, [inputState.finalTranscription])
```

### Step 4: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**.env** íŒŒì¼ì— ì¶”ê°€:

```bash
# OpenAI API Key (Whisperìš©)
OPENAI_API_KEY=sk-...

# í–¥í›„ ì¶”ê°€ë  ì„¤ì •ë“¤
# ELEVENLABS_API_KEY=...
# ELEVENLABS_VOICE_ID=...
```

### Step 5: ì˜ì¡´ì„± ì„¤ì¹˜

```bash
cd circuit
npm install form-data axios
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ê¸°ë³¸ ë…¹ìŒ/ì „ì‚¬ í…ŒìŠ¤íŠ¸

1. ì•± ì‹¤í–‰
2. ChatInputì—ì„œ Voice ë²„íŠ¼ í´ë¦­
3. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
4. ëª‡ ì´ˆê°„ ë§í•˜ê¸°
5. Voice ë²„íŠ¼ ë‹¤ì‹œ í´ë¦­ (ì¤‘ì§€)
6. ì „ì‚¬ ê²°ê³¼ í™•ì¸

**ê¸°ëŒ€ ê²°ê³¼**:
- ë…¹ìŒ ì¤‘ ë²„íŠ¼ì´ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€ê²½
- ë…¹ìŒ ì‹œê°„ í‘œì‹œ
- ì „ì‚¬ ê²°ê³¼ê°€ TranscriptionDisplayì— í‘œì‹œ
- ì‹ ë¢°ë„ í‘œì‹œ

### 2. ê°œë°œì ì½˜ì†” ë¡œê·¸ í™•ì¸

```
[VoiceContext] Starting recording...
[AudioCapture] Starting recording...
[VoiceContext] Recording started

[VoiceContext] Stopping recording...
[AudioCapture] Stopping recording...
[AudioCapture] Audio saved to: /tmp/circuit-voice/recording-xxx.webm
[Whisper] Transcribing audio: /tmp/circuit-voice/recording-xxx.webm
[Whisper] Transcription success: "ì•ˆë…•í•˜ì„¸ìš” í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"
[VoiceContext] Recording stopped. Transcription: "ì•ˆë…•í•˜ì„¸ìš” í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"
```

### 3. ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**ì‹œë‚˜ë¦¬ì˜¤ 1: OPENAI_API_KEY ì—†ìŒ**
- ê¸°ëŒ€: ì „ì‚¬ ì‹¤íŒ¨ ë©”ì‹œì§€ í‘œì‹œ
- ë¡œê·¸: `[Whisper] Transcription failed: ...`

**ì‹œë‚˜ë¦¬ì˜¤ 2: ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€**
- ê¸°ëŒ€: ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨
- ë¡œê·¸: `[AudioCapture] Failed to start recording: ...`

---

## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ (Week 1 Day 3-4)

### Intent Parser êµ¬í˜„

1. **circuit/src/lib/voice/intentParser.ts** ìƒì„±
   - GPT-4 í”„ë¡¬í”„íŠ¸ ì‘ì„±
   - ìŒì„± â†’ AgentTask[] ë³€í™˜
   - í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±

2. **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```typescript
// ì…ë ¥: "VictoriaëŠ” ë²„ê·¸ ê³ ì³ì¤˜"
// ì¶œë ¥: { agents: [{ name: 'Victoria', task: 'ë²„ê·¸ ìˆ˜ì •', ... }] }

// ì…ë ¥: "ë²„ê·¸ ê³ ì¹˜ê³  í…ŒìŠ¤íŠ¸ ì‘ì„±í•´ì¤˜"
// ì¶œë ¥: {
//   agents: [
//     { name: 'Victoria', task: 'ë²„ê·¸ ìˆ˜ì •', dependencies: [] },
//     { name: 'Alex', task: 'í…ŒìŠ¤íŠ¸ ì‘ì„±', dependencies: [0] }
//   ]
// }
```

3. **ChatInput í†µí•©**:
```typescript
const { finalTranscription } = inputState

const handleSend = async () => {
  // ìŒì„± ëª…ë ¹ íŒŒì‹±
  const parseResult = await parseVoiceCommand(finalTranscription)

  if (parseResult.isMultiAgent) {
    // ë©€í‹° ì—ì´ì „íŠ¸ ì‹¤í–‰
    await executeMultiAgentCommand(parseResult)
  } else {
    // ì¼ë°˜ ë©”ì‹œì§€ë¡œ ì „ì†¡
    setValue(finalTranscription)
  }
}
```

---

## ğŸ› ì•Œë ¤ì§„ ì´ìŠˆ

### Issue 1: ì‹¤ì œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ë¯¸êµ¬í˜„
**í˜„ìƒ**: `voice:start-recording`ì€ ìƒíƒœë§Œ ê´€ë¦¬, ì‹¤ì œ ë§ˆì´í¬ ìº¡ì²˜ ì—†ìŒ

**í•´ê²°**:
- ë Œë”ëŸ¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ MediaRecorder API ì‚¬ìš©
- `navigator.mediaDevices.getUserMedia()` í˜¸ì¶œ
- audioDataBase64ë¥¼ `voice:stop-recording`ì— ì „ë‹¬

**ìˆ˜ì • ìœ„ì¹˜**: VoiceContext.tsx

```typescript
const startRecording = async () => {
  // MediaRecorder APIë¡œ ì‹¤ì œ ë…¹ìŒ
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  const mediaRecorder = new MediaRecorder(stream)

  mediaRecorder.ondataavailable = (e) => {
    chunks.push(e.data)
  }

  mediaRecorder.start()
  // ... IPC í˜¸ì¶œ
}

const stopRecording = async () => {
  mediaRecorder.stop()

  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(chunks, { type: 'audio/webm' })
    const arrayBuffer = await audioBlob.arrayBuffer()
    const base64 = Buffer.from(arrayBuffer).toString('base64')

    // IPCë¡œ ì „ì†¡
    await ipcRenderer.invoke('voice:stop-recording', base64)
  }
}
```

### Issue 2: TTS ë¯¸êµ¬í˜„
**í˜„ìƒ**: `voice:synthesize`ê°€ stub

**í•´ê²°**: Week 2 Day 8-9ì— ElevenLabs í†µí•©

---

## ğŸ“Š ì§„í–‰ ìƒí™©

```
Week 1 Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 40%

âœ… Day 1-2: ê¸°ë³¸ ì¸í”„ë¼ (ì™„ë£Œ)
â¬œ Day 3-4: Intent Parser
â¬œ Day 5-7: Multi-Agent Orchestrator
â¬œ Week 2: TTS + UI + í†µí•©
```

---

## ğŸ’¡ ë¹ ë¥¸ ë””ë²„ê¹… íŒ

### VoiceContext ìƒíƒœ í™•ì¸
```typescript
const { inputState, feedbackState, multiAgentState } = useVoice()

console.log('Voice State:', {
  isRecording: inputState.isRecording,
  transcription: inputState.finalTranscription,
  confidence: inputState.confidence
})
```

### IPC í˜¸ì¶œ í…ŒìŠ¤íŠ¸
```javascript
// Electron ê°œë°œì ë„êµ¬ ì½˜ì†”ì—ì„œ
const { ipcRenderer } = require('electron')

// ë…¹ìŒ í…ŒìŠ¤íŠ¸
await ipcRenderer.invoke('voice:start-recording')
// ... ëª‡ ì´ˆ ëŒ€ê¸° ...
const result = await ipcRenderer.invoke('voice:stop-recording', null)
console.log(result)
```

### Whisper API ì§ì ‘ í…ŒìŠ¤íŠ¸
```bash
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@recording.webm" \
  -F model="whisper-1" \
  -F language="ko"
```

---

**ë‹¤ìŒ**: Intent Parser êµ¬í˜„ ì‹œì‘!
